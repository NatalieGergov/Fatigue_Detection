{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NatalieGergov/Fatigue_Detection/blob/main/Sequence_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Ix-q58ssEs"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5VT4k1-CvIg7",
        "outputId": "d80b6cd3-dfaa-4d01-8c1d-896a50e4c9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorlog, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.4 colorlog-6.9.0 mediapipe-0.10.14 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.4.0 protobuf-4.25.8 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "57f80f87271840cd809c0ba1942bc9bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install libraries and packages\n",
        "!pip install opencv-python mediapipe torch torchvision scikit-learn optuna\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(a, b):\n",
        "    return np.linalg.norm(np.array([a.x, a.y]) - np.array([b.x, b.y]))\n",
        "\n",
        "def calculate_ear(landmarks):\n",
        "    # EAR left\n",
        "    eye = [landmarks[i] for i in [33, 160, 158, 133, 153, 144]]\n",
        "    A = dist(eye[1], eye[5])\n",
        "    B = dist(eye[2], eye[4])\n",
        "    C = dist(eye[0], eye[3])\n",
        "    ear_left = (A + B) / (2.0 * C)\n",
        "\n",
        "    # EAR right\n",
        "    eye = [landmarks[i] for i in [362, 385, 387, 263, 373, 380]]\n",
        "    A = dist(eye[1], eye[5])\n",
        "    B = dist(eye[2], eye[4])\n",
        "    C = dist(eye[0], eye[3])\n",
        "    ear_right = (A + B) / (2.0 * C)\n",
        "\n",
        "    ear = (ear_left + ear_right) / 2.0\n",
        "    return ear\n",
        "\n",
        "def calculate_mar(landmarks):\n",
        "    mar = dist(landmarks[13], landmarks[14]) / dist(landmarks[61], landmarks[291])\n",
        "    return mar\n"
      ],
      "metadata": {
        "id": "AvAHe7JYAC1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns3qHTKos33u"
      },
      "outputs": [],
      "source": [
        "def extract_face_mesh(video_path, frame_skip=1):\n",
        "\n",
        "    # Open up facemesh\n",
        "    face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    features = []\n",
        "    frame_index = 0\n",
        "\n",
        "    while cap.isOpened() and frame_index < 3000:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if int(cap.get(cv2.CAP_PROP_POS_FRAMES)) % frame_skip != 0:\n",
        "            continue\n",
        "\n",
        "        img_rgb = frame[:, :, ::-1]\n",
        "        img_height, img_width, _ = img_rgb.shape\n",
        "        landmarks = face_mesh.process(img_rgb)\n",
        "\n",
        "        if landmarks.multi_face_landmarks:\n",
        "            landmarks_list = landmarks.multi_face_landmarks[0].landmark\n",
        "\n",
        "            # Raw landmark coords\n",
        "            coords = np.array([[lm.x, lm.y, lm.z] for lm in landmarks_list]).flatten()\n",
        "\n",
        "            ear = calculate_ear(landmarks_list)\n",
        "            mar = calculate_mar(landmarks_list)\n",
        "\n",
        "            final_features = np.concatenate([coords, [ear, mar]])\n",
        "\n",
        "            features.append(final_features)\n",
        "        else:\n",
        "            # Append a zero array with the same shape as final_features when no face is detected\n",
        "            features.append(np.zeros(1436))\n",
        "\n",
        "        frame_index += 1\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(features), fps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-lnAP9GufML"
      },
      "outputs": [],
      "source": [
        "# Build the classification dataset, with assigned binary labels\n",
        "def build_classification_dataset(video_paths, kss_scores, chunk_size=150):\n",
        "    X, y = [], []\n",
        "\n",
        "    for path, score in zip(video_paths, kss_scores):\n",
        "\n",
        "        print(f\"Processing video: {path}\")\n",
        "\n",
        "        label = int(score > 6)\n",
        "\n",
        "        tensor, fps = extract_face_mesh(path)\n",
        "        #chunks = chunk_tensor(tensor, chunk_size)\n",
        "\n",
        "        if tensor.shape[0] > 0:\n",
        "            X.append(tensor)\n",
        "            y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlB9Jkgos_st"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0cdrJ_-tA3c"
      },
      "outputs": [],
      "source": [
        "# Define LTSM and Transformer Models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1436, hidden_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        out = self.dropout(hn[-1])\n",
        "        return torch.sigmoid(self.fc(hn[-1])).squeeze(1)\n",
        "\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1436, d_model=256, nhead=8, num_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        if d_model % nhead != 0:\n",
        "            for h in range(nhead, 0, -1):\n",
        "                if d_model % h == 0:\n",
        "                    nhead = h\n",
        "                    break\n",
        "\n",
        "        self.proj = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x).permute(1, 0, 2)  # (seq, batch, d_model)\n",
        "        x = self.encoder(x)\n",
        "        return torch.sigmoid(self.fc(x[-1])).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nOyaD2XuqIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def train_classifier(model, train_loader, val_loader, epochs=5, lr=1e-3, device='cuda'):\n",
        "    model.to(device)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.float().to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).cpu().numpy()\n",
        "            y_true.extend(yb.numpy())\n",
        "            y_pred.extend((preds > 0.5).astype(int))\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return acc, f1, model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Acquistion"
      ],
      "metadata": {
        "id": "75b7m1RXgfl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze0i4ILI5AAt",
        "outputId": "bae5984d-f106-4158-f675-5477518815ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_folder = \"/content/drive/MyDrive/DROZY/videos_i8\"\n",
        "video_paths = []\n",
        "for i in range(1, 15):\n",
        "    for j in range(1, 4):\n",
        "        video_path = f\"{video_folder}/{i}-{j}.mp4\"\n",
        "        video_paths.append(video_path)\n",
        "\n",
        "kss_file_path = '/content/drive/MyDrive/DROZY/KSS.txt'\n",
        "kss_scores = []\n",
        "\n",
        "with open(kss_file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        numbers = list(map(float, line.strip().split()))\n",
        "        kss_scores.append(numbers)\n",
        "\n",
        "kss_scores = [int(num) for sublist in kss_scores for num in sublist]\n",
        "print(kss_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSQ6pfPY5FJl",
        "outputId": "1491266d-4180-4787-bc4e-b4f61ba631d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 6, 7, 3, 7, 6, 2, 3, 4, 4, 8, 9, 3, 7, 8, 2, 3, 7, 0, 4, 9, 2, 6, 8, 2, 6, 8, 3, 6, 7, 4, 7, 7, 2, 5, 6, 6, 3, 7, 5, 7, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-MG0VZzu_DT",
        "outputId": "8b1c2d81-40a4-46ce-9f42-44d44d3e71a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/1-1.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/1-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/1-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/2-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/2-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/2-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/3-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/3-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/3-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/4-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/4-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/4-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/5-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/5-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/5-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/6-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/6-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/6-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/7-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/7-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/7-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/8-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/8-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/8-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/9-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/9-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/9-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/10-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/10-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/10-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/11-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/11-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/11-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/12-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/12-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/12-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/13-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/13-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/13-3.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/14-1.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/14-2.mp4\n",
            "Processing video: /content/drive/MyDrive/DROZY/videos_i8/14-3.mp4\n"
          ]
        }
      ],
      "source": [
        "# Data setup before tuning\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "X, y = build_classification_dataset(video_paths, kss_scores, chunk_size=150)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "aIUpxUScgnA1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYD25FZWur5q"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    model_type = trial.suggest_categorical(\"model_type\", [\"lstm\", \"transformer\"])\n",
        "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512)\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "\n",
        "    # Transformer-specific constraint\n",
        "    if model_type == \"transformer\":\n",
        "        num_heads = 6  # CHANGE THIS if your model uses a different number of heads\n",
        "        if hidden_dim % num_heads != 0:\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        model = TransformerClassifier(\n",
        "            input_dim=1436,\n",
        "            d_model=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            nhead=num_heads  # Make sure your model accepts this argument\n",
        "        )\n",
        "    else:\n",
        "        model = LSTMClassifier(\n",
        "            input_dim=1436,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
        "\n",
        "    acc, f1, _ = train_classifier(model, train_loader, val_loader, epochs=5, lr=lr)\n",
        "    return 1 - f1  # minimize (to maximize F1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqIBrIGr6EJP",
        "outputId": "0c8daa6d-e780-43c3-b90f-93262afda568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9autXpbeuuZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4634eaee-e6ac-4fb8-9e6a-c6ac8ba2f8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-28 22:11:52,367] A new study created in memory with name: no-name-479eafa9-c37b-45e5-8c16-097a7c187261\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "[I 2025-07-28 22:11:58,093] Trial 0 finished with value: 0.4545454545454546 and parameters: {'model_type': 'transformer', 'hidden_dim': 222, 'num_layers': 1, 'lr': 0.000828333923548531, 'batch_size': 16}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:00,366] Trial 1 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 100, 'num_layers': 1, 'lr': 0.0025034876603867956, 'batch_size': 16}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:00,368] Trial 2 pruned. \n",
            "[I 2025-07-28 22:12:00,371] Trial 3 pruned. \n",
            "[I 2025-07-28 22:12:17,256] Trial 4 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 416, 'num_layers': 4, 'lr': 2.7473011422753835e-05, 'batch_size': 8}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:17,260] Trial 5 pruned. \n",
            "[I 2025-07-28 22:12:20,875] Trial 6 finished with value: 0.4545454545454546 and parameters: {'model_type': 'lstm', 'hidden_dim': 279, 'num_layers': 1, 'lr': 1.4466048295111769e-05, 'batch_size': 32}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:28,107] Trial 7 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 269, 'num_layers': 4, 'lr': 4.8372025993402414e-05, 'batch_size': 16}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:28,108] Trial 8 pruned. \n",
            "[I 2025-07-28 22:12:31,943] Trial 9 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 221, 'num_layers': 1, 'lr': 0.008752798619925247, 'batch_size': 16}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:31,959] Trial 10 pruned. \n",
            "[I 2025-07-28 22:12:36,791] Trial 11 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 319, 'num_layers': 2, 'lr': 0.0009702001790265147, 'batch_size': 32}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:36,807] Trial 12 pruned. \n",
            "[I 2025-07-28 22:12:43,380] Trial 13 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 326, 'num_layers': 3, 'lr': 0.00017892661845857945, 'batch_size': 32}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:48,232] Trial 14 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 183, 'num_layers': 2, 'lr': 0.0027721815831099807, 'batch_size': 32}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:48,247] Trial 15 pruned. \n",
            "[I 2025-07-28 22:12:51,819] Trial 16 finished with value: 0.4545454545454546 and parameters: {'model_type': 'lstm', 'hidden_dim': 335, 'num_layers': 1, 'lr': 0.00032376401923170096, 'batch_size': 32}. Best is trial 0 with value: 0.4545454545454546.\n",
            "/tmp/ipython-input-22-2968824849.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2) #trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
            "[I 2025-07-28 22:12:51,834] Trial 17 pruned. \n",
            "[I 2025-07-28 22:12:51,849] Trial 18 pruned. \n",
            "[I 2025-07-28 22:12:56,450] Trial 19 finished with value: 1.0 and parameters: {'model_type': 'lstm', 'hidden_dim': 250, 'num_layers': 1, 'lr': 0.00013462109013017822, 'batch_size': 8}. Best is trial 0 with value: 0.4545454545454546.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1 score: 0.5454545454545454\n",
            "Best params: {'model_type': 'transformer', 'hidden_dim': 222, 'num_layers': 1, 'lr': 0.000828333923548531, 'batch_size': 16}\n"
          ]
        }
      ],
      "source": [
        "# Run Optuna search\n",
        "import optuna\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best F1 score:\", 1 - study.best_value)\n",
        "print(\"Best params:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and evaluate model"
      ],
      "metadata": {
        "id": "ofy2BAoogr9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUAI5tr_uvuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfb811a-199f-49a6-9a9b-26f479c2c561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrained Accuracy: 0.375, F1: 0.545\n"
          ]
        }
      ],
      "source": [
        "# Final retraining with best model\n",
        "best = study.best_params\n",
        "if best[\"model_type\"] == \"lstm\":\n",
        "    model = LSTMClassifier(1436, best[\"hidden_dim\"], best[\"num_layers\"])\n",
        "else:\n",
        "    model = TransformerClassifier(1436, best[\"hidden_dim\"], num_layers=best[\"num_layers\"])\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=best[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=best[\"batch_size\"])\n",
        "\n",
        "acc, f1, model = train_classifier(model, train_loader, val_loader, epochs=10, lr=best[\"lr\"])\n",
        "print(f\"Retrained Accuracy: {acc:.3f}, F1: {f1:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label distribution:\", np.bincount(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K00aYl0FGUo",
        "outputId": "b1820617-5497-4d07-a524-35522da0c3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution: [16 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(next(model.parameters()).device)\n",
        "        preds = model(xb).round().cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "print(confusion_matrix(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSXLtaxbFGfE",
        "outputId": "87291015-31cc-45ad-ed03-86617f7efcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 5]\n",
            " [0 3]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8dsbE/bei3Ahj+rYNUGb9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}